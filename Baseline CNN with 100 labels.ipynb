{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ah_SHYAkbKvM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f0b6d6991e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_montages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/94/46dcae8c061e28be31bcaa55c560cb30ee9403c9a4bb2659768ec1b9eb7d/imutils-0.5.3.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-cp37-none-any.whl size=25850 sha256=2cbc6a5c88ab51c9cb28c18e440b96eda6ced01d60c9a764b4bbe5d3d1c5ee02\n",
      "  Stored in directory: /Users/ZN5997@engie.com/Library/Caches/pip/wheels/16/84/1f/bf88641293cda2c8be81a5c4b8ca973dd9125a6dc3767417fd\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Da1wYlIGbJKS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "width=28\n",
    "height=28\n",
    "depth=1\n",
    "classes=10\n",
    "chanDim = -1\n",
    " \n",
    "model = Sequential()\n",
    "inputShape = (height, width, depth)\n",
    "# first CONV => RELU => CONV => RELU => POOL layer set\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# first (and only) set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "# softmax classifier\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1574,
     "status": "ok",
     "timestamp": 1590247360707,
     "user": {
      "displayName": "Abdou LARBI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBb1_YSQFcHPaMLXqNvJt9IT0BN8mGlhxmUKbpMg=s64",
      "userId": "11840885257439740060"
     },
     "user_tz": -120
    },
    "id": "RGVGHB1ekxby",
    "outputId": "1169a643-07db-4cb8-d875-2d2bf16f25b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,679,082\n",
      "Trainable params: 1,677,674\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBXzc7fVcAUn"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 25\n",
    "INIT_LR = 1e-2\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2546,
     "status": "ok",
     "timestamp": 1590247362425,
     "user": {
      "displayName": "Abdou LARBI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBb1_YSQFcHPaMLXqNvJt9IT0BN8mGlhxmUKbpMg=s64",
      "userId": "11840885257439740060"
     },
     "user_tz": -120
    },
    "id": "IRsK9RQ9b_yj",
    "outputId": "95c58f79-de7e-4722-ae69-8625f4525350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST...\n",
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 85s 7us/step\n"
     ]
    }
   ],
   "source": [
    "# grab the Fashion MNIST dataset (if this is your first time running\n",
    "# this the dataset will be automatically downloaded)\n",
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
    " \n",
    "\n",
    "# if we are using \"channels first\" ordering, then reshape the design\n",
    "# matrix such that the matrix is:\n",
    "# \tnum_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "\ttestX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    " \n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    " \n",
    "trainX =  trainX[:100]\n",
    "trainY = trainY[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgPNNqSXcHHz"
   },
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    " \n",
    "# one-hot encode the training and testing labels\n",
    "trainY = np_utils.to_categorical(trainY, 10)\n",
    "testY = np_utils.to_categorical(testY, 10)\n",
    " \n",
    "# initialize the label names\n",
    "labelNames = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31627,
     "status": "ok",
     "timestamp": 1590247392127,
     "user": {
      "displayName": "Abdou LARBI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBb1_YSQFcHPaMLXqNvJt9IT0BN8mGlhxmUKbpMg=s64",
      "userId": "11840885257439740060"
     },
     "user_tz": -120
    },
    "id": "gB6emYMGcTBA",
    "outputId": "6efac3fd-9394-4b23-c5b4-0aff905efa14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "[INFO] training model...\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 100 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "100/100 [==============================] - 20s 204ms/step - loss: 3.2847 - acc: 0.1000 - val_loss: 2.8347 - val_acc: 0.2828\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.7997 - acc: 0.4500 - val_loss: 4.8858 - val_acc: 0.4495\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.8198 - acc: 0.7400 - val_loss: 6.8624 - val_acc: 0.4104\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.3871 - acc: 0.8700 - val_loss: 7.6210 - val_acc: 0.4112\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.5274 - acc: 0.8600 - val_loss: 5.7406 - val_acc: 0.5129\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.2303 - acc: 0.9200 - val_loss: 3.3485 - val_acc: 0.6616\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.2935 - acc: 0.9300 - val_loss: 3.2609 - val_acc: 0.6473\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 10s 105ms/step - loss: 0.2177 - acc: 0.9300 - val_loss: 3.8517 - val_acc: 0.5907\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 9s 87ms/step - loss: 0.1954 - acc: 0.9400 - val_loss: 3.6816 - val_acc: 0.5907\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 65s 652ms/step - loss: 0.2491 - acc: 0.9300 - val_loss: 3.2184 - val_acc: 0.6174\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 0.1474 - acc: 0.9700 - val_loss: 3.2437 - val_acc: 0.5859\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.2592 - acc: 0.9200 - val_loss: 4.7618 - val_acc: 0.4850\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.4114 - acc: 0.8700 - val_loss: 4.3318 - val_acc: 0.5095\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 0.0995 - acc: 0.9600 - val_loss: 3.4585 - val_acc: 0.5694\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.2008 - acc: 0.9300 - val_loss: 2.6570 - val_acc: 0.6337\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.0834 - acc: 0.9600 - val_loss: 2.6788 - val_acc: 0.6252\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 0.0918 - acc: 0.9800 - val_loss: 2.7766 - val_acc: 0.6082\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.1160 - acc: 0.9600 - val_loss: 2.7092 - val_acc: 0.6323\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.0384 - acc: 1.0000 - val_loss: 2.8998 - val_acc: 0.6588\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.0708 - acc: 0.9800 - val_loss: 2.8683 - val_acc: 0.6813\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.0885 - acc: 0.9800 - val_loss: 2.6566 - val_acc: 0.6921\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.1565 - acc: 0.9200 - val_loss: 2.5090 - val_acc: 0.6976\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.1833 - acc: 0.9500 - val_loss: 2.7104 - val_acc: 0.6698\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.2023 - acc: 0.9500 - val_loss: 3.5141 - val_acc: 0.5995\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 0.1878 - acc: 0.9400 - val_loss: 3.4281 - val_acc: 0.6149\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(trainX, trainY,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tbatch_size=BS, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32500,
     "status": "ok",
     "timestamp": 1590247393329,
     "user": {
      "displayName": "Abdou LARBI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBb1_YSQFcHPaMLXqNvJt9IT0BN8mGlhxmUKbpMg=s64",
      "userId": "11840885257439740060"
     },
     "user_tz": -120
    },
    "id": "5UhP_pzAdc_c",
    "outputId": "21e51da6-f058-498b-c8c7-ece4c72038c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       980\n",
      "           1       0.96      0.87      0.92      1135\n",
      "           2       0.64      0.77      0.70      1032\n",
      "           3       0.70      0.63      0.66      1010\n",
      "           4       0.46      0.80      0.58       982\n",
      "           5       0.93      0.07      0.14       892\n",
      "           6       0.98      0.20      0.33       958\n",
      "           7       0.81      0.61      0.70      1028\n",
      "           8       0.58      0.38      0.46       974\n",
      "           9       0.35      0.78      0.49      1009\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.72      0.60      0.58     10000\n",
      "weighted avg       0.72      0.61      0.59     10000\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d2319f86658e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# plot the training loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    " \n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
    "\ttarget_names=labelNames))\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1766,
     "status": "ok",
     "timestamp": 1590247342474,
     "user": {
      "displayName": "Abdou LARBI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBb1_YSQFcHPaMLXqNvJt9IT0BN8mGlhxmUKbpMg=s64",
      "userId": "11840885257439740060"
     },
     "user_tz": -120
    },
    "id": "k-zTSyRnf_y_",
    "outputId": "904cf421-b8c0-47f9-f649-d98ffb05aae5"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5130551201f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "statistics.mean(H.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2054,
     "status": "ok",
     "timestamp": 1590247312536,
     "user": {
      "displayName": "Abdou LARBI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBb1_YSQFcHPaMLXqNvJt9IT0BN8mGlhxmUKbpMg=s64",
      "userId": "11840885257439740060"
     },
     "user_tz": -120
    },
    "id": "Z5EqgDxxHSie",
    "outputId": "9301bdb5-00cb-421f-a59e-0bee85bcd761"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "\n",
    "plt.title(\"Training Accuracy on Mnist 100 sample\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2I6EMVD-H25e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN FashionMNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
